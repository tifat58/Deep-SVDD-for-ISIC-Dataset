{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "%run '/home/haal01/Desktop/Projects/Deep-SVDD-PyTorch-master/src/base/base_net.py'\n",
    "from base_net import BaseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haal01/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.],\n",
       "        [13., 14.],\n",
       "        [15., 16.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.range(1, 16)\n",
    "a = a.view(4,4)\n",
    "a = a.view(8, -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIFAR10_LeNet(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 128\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class isic_AlexNet(BaseNet):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 512\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 96, 7, bias=False, padding=1, stride=4)\n",
    "        self.bn2d1 = nn.BatchNorm2d(96)\n",
    "        self.conv2 = nn.Conv2d(96, 120, 5, padding=2)\n",
    "        self.bn2d2 = nn.BatchNorm2d(120)\n",
    "        self.conv3 = nn.Conv2d(120, 120, 3, padding=1)\n",
    "        self.bn2d3 = nn.BatchNorm2d(120)\n",
    "        self.conv4 = nn.Conv2d(120, 120, 3, padding=1)\n",
    "        self.bn2d4 = nn.BatchNorm2d(120)\n",
    "        self.conv5 = nn.Conv2d(120, 150, 3, padding=1)\n",
    "        self.bn2d5 = nn.BatchNorm2d(150)\n",
    "        self.fc1 = nn.Linear(150 * 8 * 8, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d5(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 64, 64]          14,112\n",
      "       BatchNorm2d-2           [-1, 96, 64, 64]             192\n",
      "         MaxPool2d-3           [-1, 96, 32, 32]               0\n",
      "            Conv2d-4          [-1, 120, 32, 32]         288,120\n",
      "       BatchNorm2d-5          [-1, 120, 32, 32]             240\n",
      "         MaxPool2d-6          [-1, 120, 16, 16]               0\n",
      "            Conv2d-7          [-1, 120, 16, 16]         129,720\n",
      "            Conv2d-8          [-1, 120, 16, 16]         129,720\n",
      "            Conv2d-9          [-1, 150, 16, 16]         162,150\n",
      "      BatchNorm2d-10          [-1, 150, 16, 16]             300\n",
      "        MaxPool2d-11            [-1, 150, 8, 8]               0\n",
      "           Linear-12                 [-1, 4096]      39,325,696\n",
      "           Linear-13                 [-1, 2048]       8,390,656\n",
      "           Linear-14                  [-1, 512]       1,049,088\n",
      "================================================================\n",
      "Total params: 49,489,994\n",
      "Trainable params: 49,489,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.76\n",
      "Forward/backward pass size (MB): 10.04\n",
      "Params size (MB): 188.79\n",
      "Estimated Total Size (MB): 199.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m1 = isic_AlexNet()\n",
    "m1.cuda()\n",
    "summary(m1, (3, 257, 257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISIC_VGG16(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 1000\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, bias=False, padding=1)\n",
    "        self.bn2d1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2d3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn2d4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn2d5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn2d6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn2d7 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.bn2d8 = nn.BatchNorm2d(512)\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d9 = nn.BatchNorm2d(512)\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d10 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d11 = nn.BatchNorm2d(512)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d12 = nn.BatchNorm2d(512)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d13 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096, bias=True)\n",
    "        self.fc2 = nn.Linear(4096, 4096, bias=True)\n",
    "        self.fc3 = nn.Linear(4096, self.rep_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2d1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2d3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d4(x)))\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn2d5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn2d6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d7(x)))\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn2d8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn2d9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d10(x)))\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn2d11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.bn2d12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d13(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class ISIC_VGG16_Autoencoder(BaseNet):\n",
    "    # vgg 16 au\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 1000\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, bias=False, padding=1)\n",
    "        self.bn2d1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2d3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn2d4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn2d5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn2d6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn2d7 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.bn2d8 = nn.BatchNorm2d(512)\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d9 = nn.BatchNorm2d(512)\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d10 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d11 = nn.BatchNorm2d(512)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d12 = nn.BatchNorm2d(512)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2d13 = nn.BatchNorm2d(512)\n",
    "\n",
    "#         self.fc1 = nn.Linear(512 * 7 * 7, 4096, bias=True)\n",
    "#         self.fc2 = nn.Linear(4096, 4096, bias=True)\n",
    "#         self.fc3 = nn.Linear(4096, self.rep_dim, bias=True)\n",
    "\n",
    "#         # decoder\n",
    "#         self.dfc1 = nn.Linear(self.rep_dim, 4096)\n",
    "#         self.dfc2 = nn.Linear(4096, 4096)\n",
    "#         self.dfc3 = nn.Linear(4096, 25088)\n",
    "\n",
    "#         for testing block\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, self.rep_dim, bias=True)\n",
    "        self.dfc1 = nn.Linear(self.rep_dim, 25088)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(int(25088 / (7 * 7)), 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d14 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d15 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv3 = nn.ConvTranspose2d(512, 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d16 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv4 = nn.ConvTranspose2d(512, 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d17 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv5 = nn.ConvTranspose2d(512, 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv5.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d18 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv6 = nn.ConvTranspose2d(512, 512, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv6.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d19 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.deconv7 = nn.ConvTranspose2d(512, 256, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv7.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d20 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.deconv8 = nn.ConvTranspose2d(256, 256, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv8.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d21 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.deconv9 = nn.ConvTranspose2d(256, 256, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv9.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d22 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.deconv10 = nn.ConvTranspose2d(256, 128, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv10.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d23 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.deconv11 = nn.ConvTranspose2d(128, 128, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv11.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d24 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.deconv12 = nn.ConvTranspose2d(128, 64, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv12.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d25 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.deconv13 = nn.ConvTranspose2d(64, 64, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv13.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d26 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.deconv14 = nn.ConvTranspose2d(64, 3, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv14.weight, gain=nn.init.calculate_gain(('leaky_relu')))\n",
    "        self.bn2d27 = nn.BatchNorm2d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2d1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2d3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d4(x)))\n",
    "        \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.bn2d5(x)\n",
    "#         x = self.conv6(x)\n",
    "#         x = self.bn2d6(x)\n",
    "#         x = self.conv7(x)\n",
    "#         x = self.pool(F.leaky_relu(self.bn2d7(x)))\n",
    "#         x = self.conv8(x)\n",
    "#         x = self.bn2d8(x)\n",
    "#         x = self.conv9(x)\n",
    "#         x = self.bn2d9(x)\n",
    "#         x = self.conv10(x)\n",
    "#         x = self.pool(F.leaky_relu(self.bn2d10(x)))\n",
    "#         x = self.conv11(x)\n",
    "#         x = self.bn2d11(x)\n",
    "#         x = self.conv12(x)\n",
    "#         x = self.bn2d12(x)\n",
    "#         x = self.conv13(x)\n",
    "#         x = self.pool(F.leaky_relu(self.bn2d13(x)))\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        return x\n",
    "        x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "\n",
    "        x = self.dfc1(x)\n",
    "#         x = self.dfc2(x)\n",
    "#         x = self.dfc3(x)\n",
    "        x = x.view(x.size(0), int(25088 / (7 * 7)), 7, 7)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d14(x)), scale_factor=2)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.bn2d15(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d16(x)), scale_factor=2)\n",
    "        x = self.deconv4(x)\n",
    "        x = self.bn2d17(x)\n",
    "        x = self.deconv5(x)\n",
    "        x = self.bn2d18(x)\n",
    "        x = self.deconv6(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d19(x)), scale_factor=2)\n",
    "        x = self.deconv7(x)\n",
    "        x = self.bn2d20(x)\n",
    "        x = self.deconv8(x)\n",
    "        x = self.bn2d21(x)\n",
    "        x = self.deconv9(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d22(x)), scale_factor=2)\n",
    "        x = self.deconv10(x)\n",
    "        x = self.bn2d23(x)\n",
    "        x = self.deconv11(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d24(x)), scale_factor=2)\n",
    "        x = self.deconv12(x)\n",
    "        x = self.bn2d25(x)\n",
    "        x = self.deconv13(x)\n",
    "        x = self.bn2d26(x)\n",
    "        x = self.deconv14(x)\n",
    "        x = self.bn2d27(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [2 x 401408], m2: [25088 x 1000] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5f1634a059ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mISIC_VGG16_Autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3d898a8bf7b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;31m#         x = self.fc2(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m#         x = self.fc3(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [2 x 401408], m2: [25088 x 1000] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "m1 = ISIC_VGG16_Autoencoder()\n",
    "m1.cuda()\n",
    "summary(m1, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class isic_AlexNet_Autoencoder(BaseNet):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.rep_dim = 512\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        \n",
    "        # encoder\n",
    "        self.conv1 = nn.Conv2d(3, 96, 7, bias=False, padding=1, stride=4)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d1 = nn.BatchNorm2d(96)\n",
    "        self.conv2 = nn.Conv2d(96, 120, 5, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d2 = nn.BatchNorm2d(120)\n",
    "        self.conv3 = nn.Conv2d(120, 120, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d3 = nn.BatchNorm2d(120)\n",
    "        self.conv4 = nn.Conv2d(120, 120, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.conv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d4 = nn.BatchNorm2d(120)\n",
    "        self.conv5 = nn.Conv2d(120, 150, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.conv5.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d5 = nn.BatchNorm2d(150)\n",
    "        self.fc1 = nn.Linear(150 * 8 * 8, 9600)\n",
    "        self.fc2 = nn.Linear(9600, 2048)\n",
    "        self.fc3 = nn.Linear(2048, self.rep_dim)\n",
    "        \n",
    "        # decoder \n",
    "        self.dfc1 = nn.Linear(self.rep_dim, 2048)\n",
    "        self.dfc2 = nn.Linear(2048, 9600)\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose2d(int(9600 / (8 * 8)), 150, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d6 = nn.BatchNorm2d(150)\n",
    "        \n",
    "        self.deconv2 = nn.ConvTranspose2d(150, 120, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d7 = nn.BatchNorm2d(120)\n",
    "        \n",
    "        self.deconv3 = nn.ConvTranspose2d(120, 120, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d8 = nn.BatchNorm2d(120)\n",
    "        \n",
    "        self.deconv4 = nn.ConvTranspose2d(120, 120, 3, padding=1)\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d9 = nn.BatchNorm2d(120)\n",
    "        \n",
    "        self.deconv5 = nn.ConvTranspose2d(120, 96, 5, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv5.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d10 = nn.BatchNorm2d(96)\n",
    "        \n",
    "        self.deconv6 = nn.ConvTranspose2d(96, 3, 7, padding=1, stride=4)\n",
    "        nn.init.xavier_uniform_(self.deconv6.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d5(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dfc1(x)\n",
    "        x = self.dfc2(x)\n",
    "        x = x.view(x.size(0), int(9600 / (8 * 8)), 8, 8)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.deconv1(x)\n",
    "\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d6(x)), scale_factor=2)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d7(x)), scale_factor=2)\n",
    "        x = self.deconv3(x)\n",
    "      \n",
    "        x = self.deconv4(x)\n",
    "    \n",
    "        x = self.deconv5(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d10(x)), scale_factor=2)\n",
    "        x = self.deconv6(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isic_AlexNet_Autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-da3827519d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misic_AlexNet_Autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m257\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m257\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'isic_AlexNet_Autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "m2 = isic_AlexNet_Autoencoder()\n",
    "m2.cuda()\n",
    "summary(m2, (3, 257, 257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_LeNet_Autoencoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 128\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Encoder (must match the Deep SVDD network above)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, self.rep_dim, bias=False)\n",
    "        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim / (32 * 32)), 128, 5, bias=False, padding=2)\n",
    "    \n",
    "        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d4 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d5 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d6 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.bn1d(self.fc1(x))\n",
    "        x = x.view(-1, int(self.rep_dim / (32 * 32)), 4, 4)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d4(x)), scale_factor=2)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d5(x)), scale_factor=2)\n",
    "        x = self.deconv3(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d6(x)), scale_factor=2)\n",
    "        x = self.deconv4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_LeNet_ELU_Autoencoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 128\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Encoder (must match the Deep SVDD network above)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, self.rep_dim, bias=False)\n",
    "        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim), 128, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv1.weight)\n",
    "        self.bn2d4 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight)\n",
    "        self.bn2d5 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight)\n",
    "        self.bn2d6 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.elu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.elu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(F.elu(self.bn2d3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.bn1d(self.fc1(x))\n",
    "        x = x.view(x.size(0), int(self.rep_dim / (32 * 32)), 4, 4)\n",
    "        x = F.elu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.interpolate(F.elu(self.bn2d4(x)), scale_factor=2)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.interpolate(F.elu(self.bn2d5(x)), scale_factor=2)\n",
    "        x = self.deconv3(x)\n",
    "        x = F.interpolate(F.elu(self.bn2d6(x)), scale_factor=2)\n",
    "        x = self.deconv4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8b700bd7117f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10_LeNet_Autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-db9ba80d086b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrep_dim\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, groups, bias, dilation)\u001b[0m\n\u001b[1;32m    683\u001b[0m         super(ConvTranspose2d, self).__init__(\n\u001b[1;32m    684\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             True, output_padding, groups, bias)\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/deep-svdd-env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mstdv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstdv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "m1 = CIFAR10_LeNet_Autoencoder()\n",
    "m1.cuda()\n",
    "summary(m1, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_LeNet_ELU(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 128\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(128 * 4 *4, self.rep_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.elu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.elu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(F.elu(self.bn2d3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def flatten_output(self, x):\n",
    "        \n",
    "        X = x.view(x.size(0), -1)\n",
    "        print(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [3]])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]           2,400\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]               0\n",
      "         MaxPool2d-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          51,200\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]         204,800\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
      "           Linear-10                  [-1, 128]         262,144\n",
      "================================================================\n",
      "Total params: 520,544\n",
      "Trainable params: 520,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 37.64\n",
      "Params size (MB): 1.99\n",
      "Estimated Total Size (MB): 40.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m1 = CIFAR10_LeNet_ELU()\n",
    "m1.cuda()\n",
    "a = np.array([2,3])\n",
    "a = torch.from_numpy(a)\n",
    "m1.flatten_output(a)\n",
    "summary(m1, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_LeNet_Autoencoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rep_dim = 128\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        # Encoder (must match the Deep SVDD network above)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.conv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n",
    "        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n",
    "\n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim / (4 * 4)), 128, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d4 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d5 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "        self.bn2d6 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n",
    "        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(F.leaky_relu(self.bn2d3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.bn1d(self.fc1(x))\n",
    "        x = x.view(x.size(0), int(self.rep_dim / (4 * 4)), 4, 4)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d4(x)), scale_factor=4)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d5(x)), scale_factor=4)\n",
    "        x = self.deconv3(x)\n",
    "        x = F.interpolate(F.leaky_relu(self.bn2d6(x)), scale_factor=4)\n",
    "        x = self.deconv4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]           2,400\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]               0\n",
      "         MaxPool2d-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 64, 64, 64]          51,200\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]         204,800\n",
      "       BatchNorm2d-8          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
      "           Linear-10                  [-1, 128]         262,144\n",
      "      BatchNorm1d-11                  [-1, 128]               0\n",
      "  ConvTranspose2d-12            [-1, 128, 4, 4]          25,600\n",
      "      BatchNorm2d-13            [-1, 128, 4, 4]               0\n",
      "  ConvTranspose2d-14           [-1, 64, 16, 16]         204,800\n",
      "      BatchNorm2d-15           [-1, 64, 16, 16]               0\n",
      "  ConvTranspose2d-16           [-1, 32, 64, 64]          51,200\n",
      "      BatchNorm2d-17           [-1, 32, 64, 64]               0\n",
      "  ConvTranspose2d-18          [-1, 3, 256, 256]           2,400\n",
      "================================================================\n",
      "Total params: 804,544\n",
      "Trainable params: 804,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 41.42\n",
      "Params size (MB): 3.07\n",
      "Estimated Total Size (MB): 45.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m1 = CIFAR10_LeNet_Autoencoder()\n",
    "m1.cuda()\n",
    "summary(m1, (3, 256, 256))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
